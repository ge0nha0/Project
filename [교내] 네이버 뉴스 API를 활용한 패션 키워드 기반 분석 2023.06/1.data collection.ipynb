{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8289e61",
   "metadata": {},
   "source": [
    "# 1. 데이터 수집\n",
    "## Naver News \n",
    "### Naver API와 BeautifulSoup을 활용\n",
    "#### 데이터 수집은 Jupyter Notebook에서 돌렸고, csv 파일을 구글 드라이브에 옮겼습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493b4a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import urllib.request\n",
    "import time\n",
    "import json\n",
    "import re\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2372bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "client_id = # client id \n",
    "client_secret = # client secret\n",
    "\n",
    "base_url = 'https://openapi.naver.com/v1/search/news.json'\n",
    "query = '영국패션' # 검색할 키워드 \n",
    "encQuery = urllib.parse.quote(query.encode('utf-8')) \n",
    "n_display = 10 # 한 번에 보여줄 검색 결과 수\n",
    "sort = 'sim' # 검색 결과 정렬 방식\n",
    "search_result_li = []  # 검색 결과를 저장할 리스트\n",
    "\n",
    "for start in range(1,999,10): #1~100페이지\n",
    "    url = f'{base_url}?query={encQuery}&display={n_display}&start={start}&sort={sort}'\n",
    "    my_request = urllib.request.Request(url)  # URL로 요청 객체 생성\n",
    "    my_request.add_header(\"X-Naver-Client-Id\",client_id)  # Client-Id 헤더 추가\n",
    "    my_request.add_header(\"X-Naver-Client-Secret\",client_secret)  # Client Secret 헤더 추가\n",
    "    response = urllib.request.urlopen(my_request) # 요청 보내고 응답 받음\n",
    "    rescode = response.getcode() # 응답 상태 코드 확인\n",
    "  \n",
    "    if(rescode==200):  # 응답이 성공적으로 받아온 경우\n",
    "        response_body = response.read()  # 응답 데이터 읽기\n",
    "    else:\n",
    "        print(\"Error Code:\" + rescode)  # 응답이 정상적이지 않을 경우 에러 코드 출력\n",
    "    search_result_str = response_body.decode('utf-8')  # 응답 데이터를 문자열로 디코딩\n",
    "    search_results = json.loads(search_result_str)  # JSON 형식의 응답 데이터를 파싱하여 Python 객체로 변환\n",
    "    search_result_li.append(search_results)  # 검색 결과를 리스트에 추가\n",
    "print(search_result_li) # 모든 검색 결과를 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa257b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles_li = [] # 뉴스 제목을 저장할 리스트\n",
    "links_li = []  # 뉴스 링크를 저장할 리스트\n",
    "\n",
    "for result in search_result_li:  # 이전에 검색한 모든 검색 결과에 대해 반복\n",
    "    titles = []  # 현재 검색 결과의 뉴스 제목을 저장할 리스트\n",
    "    links = []   # 현재 검색 결과의 뉴스 링크를 저장할 리스트\n",
    "    p = re.compile('https://n.news.naver.com/.+')  # 정규표현식을 사용하여 네이버 뉴스 링크인지 확인하는 패턴 생성\n",
    "    for item in result['items']:\n",
    "        if p.match(item['link']):  # item의 링크가 네이버 뉴스 링크인지 확인\n",
    "            title = item['title']  # item의 제목 추출\n",
    "            link = item['link']    # item의 링크 추출\n",
    "            titles.append(title)   # 현재 검색 결과의 뉴스 제목 리스트에 추가\n",
    "            links.append(link)     # 현재 검색 결과의 뉴스 링크 리스트에 추가\n",
    "    titles_li += titles            # 현재 검색 결과의 뉴스 제목 리스트를 전체 뉴스 제목 리스트에 추가\n",
    "    links_li += links              # 현재 검색 결과의 뉴스 링크 리스트를 전체 뉴스 링크 리스트에 추가\n",
    "\n",
    "print('뉴스 개수 :' ,len(links_li))  # 전체 뉴스 개수 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95eb9531",
   "metadata": {},
   "outputs": [],
   "source": [
    "article_ids = ['newsct_article', 'articeBody']\n",
    "contents = []\n",
    "\n",
    "for link in tqdm(links_li):  # 이전에 수집한 모든 뉴스 링크에 대해 반복\n",
    "    html = urllib.request.urlopen(link)         # 뉴스 링크로부터 HTML 데이터 가져오기\n",
    "    bs_obj = BeautifulSoup(html, 'html.parser') # BeautifulSoup를 사용하여 HTML 파싱\n",
    "    for article_id in article_ids:  # 본문을 찾기 위한 HTML 요소의 id 리스트에 대해 반복\n",
    "        content = bs_obj.find_all('div', {'id':article_id})\n",
    "        if len(content) > 0:   # 해당 id를 가진 HTML 요소를 찾은 경우\n",
    "            contents.append(content[0].text)   # 첫 번째 HTML 요소의 텍스트를 뉴스 본문 리스트에 추가\n",
    "            break\n",
    "        else:   # 해당 id를 가진 HTML 요소를 찾지 못한 경우\n",
    "            continue\n",
    "        time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c8f44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dict = {'제목': titles_li, '내용': contents}\n",
    "df = pd.DataFrame.from_dict(result_dict)\n",
    "print(len(df))\n",
    "df # dataframe 형태로 만듬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f7e64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('{}_뉴스.csv'.format(query),encoding='utf-8-sig',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e552bc",
   "metadata": {},
   "source": [
    "## Colab 패키지 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1136bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de75e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install konlpy\n",
    "!pip install wordcloud\n",
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0b45e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 코랩 패키지 버전 확인\n",
    "!pip show konlpy # 0.6.0\n",
    "!pip show wordcloud #1.8.2.2\n",
    "!pip show nltk # 3.8.1\n",
    "!python --version # 3.10.11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8550b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs_10 = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Naver_뉴스_패션/data/10대패션_뉴스.csv')\n",
    "fs_20 = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Naver_뉴스_패션/data/20대패션_뉴스.csv')\n",
    "fs_30 = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Naver_뉴스_패션/data/30대패션_뉴스.csv')\n",
    "fs_40 = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Naver_뉴스_패션/data/40대패션_뉴스.csv')\n",
    "fs_50 = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Naver_뉴스_패션/data/50대패션_뉴스.csv')\n",
    "\n",
    "fs_1980 = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Naver_뉴스_패션/data/1980년대패션_뉴스.csv')\n",
    "fs_1990 = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Naver_뉴스_패션/data/1990년대패션_뉴스.csv')\n",
    "fs_2000 = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Naver_뉴스_패션/data/2000년대패션_뉴스.csv')\n",
    "fs_2010 = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Naver_뉴스_패션/data/2010년대패션_뉴스.csv')\n",
    "fs_2020 = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Naver_뉴스_패션/data/2020패션_뉴스.csv')\n",
    "\n",
    "fs_m = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Naver_뉴스_패션/data/남자패션_뉴스.csv')\n",
    "fs_w = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Naver_뉴스_패션/data/여자패션_뉴스.csv')\n",
    "\n",
    "fs_sp = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Naver_뉴스_패션/data/봄패션_뉴스.csv')\n",
    "fs_su = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Naver_뉴스_패션/data/여름패션_뉴스.csv')\n",
    "fs_au = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Naver_뉴스_패션/data/가을패션_뉴스.csv')\n",
    "fs_wi = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Naver_뉴스_패션/data/겨울패션_뉴스.csv')\n",
    "\n",
    "fs_usa = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Naver_뉴스_패션/data/미국패션_뉴스.csv')\n",
    "fs_jap = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Naver_뉴스_패션/data/일본패션_뉴스.csv')\n",
    "fs_fra = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Naver_뉴스_패션/data/프랑스패션_뉴스.csv')\n",
    "fs_ita = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Naver_뉴스_패션/data/이탈리아패션_뉴스.csv')\n",
    "fs_eng = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Naver_뉴스_패션/data/영국패션_뉴스.csv')\n",
    "\n",
    "fs_spa = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Naver_뉴스_패션/data/SPA_뉴스.csv')\n",
    "fs_nike = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Naver_뉴스_패션/data/나이키_뉴스.csv')\n",
    "fs_lux = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Naver_뉴스_패션/data/명품_뉴스.csv') \n",
    "fs_work = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Naver_뉴스_패션/data/패션워크_뉴스.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08ae8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fs_10.shape)\n",
    "print(fs_20.shape)\n",
    "print(fs_30.shape)\n",
    "print(fs_40.shape)\n",
    "print(fs_50.shape)\n",
    "\n",
    "print(fs_1980.shape)\n",
    "print(fs_1990.shape)\n",
    "print(fs_2000.shape)\n",
    "print(fs_2010.shape)\n",
    "print(fs_2020.shape)\n",
    "\n",
    "print(fs_m.shape)\n",
    "print(fs_w.shape)\n",
    "\n",
    "print(fs_sp.shape)\n",
    "print(fs_su.shape)\n",
    "print(fs_au.shape)\n",
    "print(fs_wi.shape)\n",
    "\n",
    "print(fs_usa.shape)\n",
    "print(fs_jap.shape)\n",
    "print(fs_fra.shape)\n",
    "print(fs_ita.shape)\n",
    "print(fs_eng.shape)\n",
    "\n",
    "print(fs_spa.shape)\n",
    "print(fs_nike.shape)\n",
    "print(fs_lux.shape)\n",
    "print(fs_work.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c30f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 키워드 열 추가하기 -> drop_duplicates 후에 키워드 별로 정리할 때 편하게 하기 위함\n",
    "fs_10['키워드'] = '10대패션'\n",
    "fs_20['키워드'] = '20대패션'\n",
    "fs_30['키워드'] = '30대패션'\n",
    "fs_40['키워드'] = '40대패션'\n",
    "fs_50['키워드'] = '50대패션'\n",
    "\n",
    "fs_1980['키워드'] = '1980년대패션'\n",
    "fs_1990['키워드'] = '1990년대패션'\n",
    "fs_2000['키워드'] = '2000년대패션'\n",
    "fs_2010['키워드'] = '2010년대패션'\n",
    "fs_2020['키워드'] = '2020년대패션'\n",
    "\n",
    "fs_m['키워드'] = '남자패션'\n",
    "fs_w['키워드'] = '여자패션'\n",
    "\n",
    "fs_sp['키워드'] = '봄패션'\n",
    "fs_su['키워드'] = '여름패션'\n",
    "fs_au['키워드'] = '가을패션'\n",
    "fs_wi['키워드'] = '겨울패션'\n",
    "\n",
    "fs_usa['키워드'] = '미국패션'\n",
    "fs_jap['키워드'] = '일본패션'\n",
    "fs_fra['키워드'] = '프랑스패션'\n",
    "fs_ita['키워드'] = '이탈리아패션'\n",
    "fs_eng['키워드'] = '영국패션'\n",
    "\n",
    "fs_spa['키워드'] = 'SPA'\n",
    "fs_nike['키워드'] = '나이키'\n",
    "fs_lux['키워드'] = '명품'\n",
    "fs_work['키워드'] = '패션워크'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
